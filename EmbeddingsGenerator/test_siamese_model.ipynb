{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from classes.embeddings_model import EmbeddingsModel, PainDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "from pytorch_metric_learning import distances, losses, miners, reducers, testers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(data)\n",
    "        indices_tuple = mining_func(embeddings, labels)\n",
    "        loss = loss_func(embeddings, labels, indices_tuple)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(\n",
    "                \"Epoch {} Iteration {}: Loss = {}, Number of mined triplets = {}\".format(\n",
    "                    epoch, batch_idx, loss, mining_func.num_triplets\n",
    "                )\n",
    "            )\n",
    "\n",
    "def get_all_embeddings(dataset, model):\n",
    "    tester = testers.BaseTester()\n",
    "    return tester.get_all_embeddings(dataset, model)\n",
    "\n",
    "def test(train_set, test_set, model, accuracy_calculator):\n",
    "    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n",
    "    test_embeddings, test_labels = get_all_embeddings(test_set, model)\n",
    "    train_labels = train_labels.squeeze(1)\n",
    "    test_labels = test_labels.squeeze(1)\n",
    "    print(\"Computing accuracy\")\n",
    "    accuracies = accuracy_calculator.get_accuracy(\n",
    "        test_embeddings, train_embeddings, test_labels, train_labels, False\n",
    "    )\n",
    "    print(\"Test set accuracy (Precision@1) = {}\".format(accuracies[\"precision_at_1\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects = ['S001', 'S002', 'S003', 'S004', 'S005', 'S006', 'S007', 'S008',\n",
    "                'S009', 'S010', 'S011', 'S012', 'S013', 'S014', 'S015', 'S016',\n",
    "                'S017', 'S018', 'S019', 'S020', 'S021', 'S022', 'S023', 'S024',\n",
    "                'S025', 'S026', 'S027', 'S029', 'S031', 'S032', 'S033', 'S034',\n",
    "                'S035', 'S036', 'S037', 'S038', 'S039', 'S040', 'S041', 'S042',\n",
    "                'S043', 'S044', 'S045', 'S046', 'S047', 'S048', 'S049', 'S050',\n",
    "                'S051', 'S052', 'S053', 'S054', 'S055', 'S056', 'S057', 'S058',\n",
    "                'S060', 'S061', 'S062', 'S063', 'S064', 'S065', 'S066', 'S067',\n",
    "                'S068', 'S069', 'S070', 'S071', 'S072', 'S073', 'S074', 'S075',\n",
    "                'S076', 'S077', 'S078', 'S079', 'S080', 'S081', 'S082', 'S083',\n",
    "                'S084', 'S085', 'S086', 'S087', 'S088', 'S089', 'S090', 'S091',\n",
    "                'S092', 'S093', 'S094', 'S095', 'S096', 'S097', 'S098', 'S099',\n",
    "                'S100', 'S101', 'S102', 'S103', 'S104', 'S105', 'S106', 'S107',\n",
    "                'S109', 'S110', 'S111', 'S112', 'S113', 'S114', 'S115', 'S116',\n",
    "                'S117', 'S118', 'S119', 'S120', 'S121', 'S122', 'S123', 'S124',\n",
    "                'S125', 'S126', 'S127', 'S128', 'S129', 'S130', 'S131', 'S132',\n",
    "                'S133', 'S134']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "batch_size = 256\n",
    "path = \"D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\FeatureGeneration\\dataset_processed\\XITE\\\\normalized_subjects.pkl\"\n",
    "subjects_valid = [all_subjects[0]]\n",
    "subjects_train = [sub for sub in all_subjects if sub not in subjects_valid]\n",
    "\n",
    "\n",
    "dataset1 = PainDataset(path, subjects=subjects_train)\n",
    "train_loader = DataLoader(dataset1, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset2 = PainDataset(path, subjects=subjects_valid)\n",
    "test_loader = DataLoader(dataset2, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning.distances import SNRDistance\n",
    "from pytorch_metric_learning.utils.inference import CustomKNN\n",
    "\n",
    "knn_func = CustomKNN(SNRDistance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmbeddingsModel().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "distance = distances.CosineSimilarity()\n",
    "reducer = reducers.ThresholdReducer(low=0)\n",
    "loss_func = losses.TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)\n",
    "mining_func = miners.TripletMarginMiner(margin=0.2, distance=distance, type_of_triplets=\"semihard\")\n",
    "\n",
    "\n",
    "\n",
    "accuracy_calculator = AccuracyCalculator(include=(\"r_precision\",), k=1, knn_func=knn_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    #train(model, loss_func, mining_func, device, train_loader, optimizer, epoch)\n",
    "    test(dataset1, dataset2, model, accuracy_calculator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4eef61a7b0f179811b21666adaca2eddf4327132c8a5532deea9676baf493691"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
