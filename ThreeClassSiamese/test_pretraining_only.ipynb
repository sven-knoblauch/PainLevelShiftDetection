{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\Classes')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from models import ClassificationModel, EmbeddingsModel, SiameseModel\n",
    "from trainer import SiameseTrainerThreeClass, all_subjects, all_subjects_intense\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import torch\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all models\n",
    "path = \"D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\ThreeClassSiamese\\pretrained_models\\\\\"\n",
    "all_files = [f for f in listdir(path) if isfile(join(path, f))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSO - INTENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:04<00:00,  5.98it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 13.19it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 14.95it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 14.32it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 12.31it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 13.71it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.28it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.00it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 12.39it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 13.28it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 12.93it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 12.94it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 13.24it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 12.93it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 12.93it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 12.91it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 13.71it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 13.42it/s]\n"
     ]
    }
   ],
   "source": [
    "#load each model\n",
    "for file in all_files:\n",
    "    model_path = path+file\n",
    "    saving_path = \"D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\ThreeClassSiamese\\\\results\\\\no_finetuning\\\\\"+file[:-4]+\".csv\"\n",
    "    model_path = \"D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\ThreeClassSiamese\\pretrained_models\\\\\"+file\n",
    "\n",
    "    #generate file for LOSO results\n",
    "    with open(saving_path, mode='a') as result_file:\n",
    "        results_writer = csv.writer(result_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        results_writer.writerow([\"subj\", \"accuracy\", \"cm\"])\n",
    "\n",
    "    #LOSO for testing\n",
    "    for subj in tqdm(all_subjects_intense):\n",
    "        subjects_test = [subj]\n",
    "        subjects_train = [sub for sub in all_subjects_intense if sub not in subjects_test]\n",
    "\n",
    "        trainer_hyperparameter = {\n",
    "            \"path\": \"D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\FeatureGeneration\\dataset_processed\\INTENSE2\\\\normalized_subjects.pkl\",\n",
    "            \"subjects_train\": subjects_train,\n",
    "            \"subjects_test\": subjects_test,\n",
    "            \"intense_dataset_train\": True,\n",
    "            \"intense_dataset_test\": True,\n",
    "            \"xite_2class_train\": False,\n",
    "            \"xite_2class_test\": False,\n",
    "            \"indices1_train\": 4,\n",
    "            \"indices2_train\": 1,\n",
    "            \"indices1_test\": 1,\n",
    "            \"indices2_test\": 0,\n",
    "            \"use_regression\": False,\n",
    "            \"wandb\": False,\n",
    "            \"log\": False,\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"batch_size\": 256,\n",
    "            \"batch_size_test\": 256,\n",
    "            \"freeze_embed\": False,\n",
    "            \"decision_function\": 3,\n",
    "            \"filter\": [],\n",
    "            \"weight_decay\": 0,\n",
    "            \"lr_steps\": 10,\n",
    "            \"number_steps\": 400,\n",
    "            \"number_steps_testing\": None\n",
    "        }\n",
    "\n",
    "        model_embedding_hyperparameter = {\n",
    "                \"sigmoid\": False,\n",
    "                \"dropout\": 0.35,\n",
    "                \"layers\": [207, 512, 64]\n",
    "        }\n",
    "\n",
    "        if trainer_hyperparameter[\"use_regression\"]:\n",
    "            head = 1\n",
    "        else:\n",
    "            head=2\n",
    "\n",
    "        model_classifier_hyperparameter = {\n",
    "            \"dropout\": 0.35,\n",
    "            \"layers\": [64, 32],\n",
    "            \"head_type\": head\n",
    "        }\n",
    "\n",
    "        classifier_model = ClassificationModel(model_classifier_hyperparameter)\n",
    "        embedding_model = EmbeddingsModel(model_embedding_hyperparameter)\n",
    "        siamese_model = SiameseModel(embedding_model, classifier_model, decision_function=trainer_hyperparameter[\"decision_function\"])\n",
    "        \n",
    "        _ = siamese_model.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "        trainer = SiameseTrainerThreeClass(trainer_hyperparameter, siamese_model, device=\"cuda:0\")\n",
    "\n",
    "        #test network and get results\n",
    "        res = trainer.test()\n",
    "        cm = res[\"cm\"]\n",
    "        acc = res[\"acc\"]\n",
    "\n",
    "        #normalice cm\n",
    "        s = np.sum(cm, axis=1)\n",
    "        cm = cm.astype('float64')\n",
    "        cm[0] = cm[0]/s[0]\n",
    "        cm[1] = cm[1]/s[1]\n",
    "        cm[2] = cm[2]/s[2]\n",
    "\n",
    "        with open(saving_path, mode='a') as result_file:\n",
    "            results_writer = csv.writer(result_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            results_writer.writerow([subj, acc*100, cm])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15553fa20e7e98b2aa17988b3683b9c4372a086618e2f531c95263c140b6e43e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
