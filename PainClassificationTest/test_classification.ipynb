{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\Classes')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from models import EmbeddingsModel\n",
    "from trainer import EmbeddingTrainer, all_subjects, AccuracyTester, all_subjects_intense\n",
    "from pytorch_metric_learning import distances\n",
    "\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from functools import partialmethod\n",
    "tqdm.__init__ = partialmethod(tqdm.__init__, disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_model = True\n",
    "\n",
    "saving_path = \"D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\PainClassificationTest\\Results\\\\intense_embedding2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init file\n",
    "#with open(saving_path, mode='w') as result_file:\n",
    "#    results_writer = csv.writer(result_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#    results_writer.writerow([\"subject\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_processed = list(pd.read_csv(saving_path)[\"subject\"])\n",
    "not_processed = [sub for sub in all_subjects_intense if sub not in already_processed]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Split Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 207)) while a minimum of 1 is required by RandomForestClassifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 56\u001b[0m\n\u001b[0;32m     49\u001b[0m     acc_tester_hyperparameter \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mWorkspace\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mworkspace_masterarbeit\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPainLevelShiftDetection\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFeatureGeneration\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdataset_processed\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mINTENSE\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mnormalized_subjects_no_outliner.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubjects_train\u001b[39m\u001b[38;5;124m\"\u001b[39m: subjects_train,\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubjects_test\u001b[39m\u001b[38;5;124m\"\u001b[39m: subjects_test\n\u001b[0;32m     53\u001b[0m     }\n\u001b[0;32m     54\u001b[0m     acc_tester \u001b[38;5;241m=\u001b[39m AccuracyTester(acc_tester_hyperparameter, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m     acc \u001b[38;5;241m=\u001b[39m \u001b[43macc_tester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(saving_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m result_file:\n\u001b[0;32m     59\u001b[0m     results_writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(result_file, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, quoting\u001b[38;5;241m=\u001b[39mcsv\u001b[38;5;241m.\u001b[39mQUOTE_MINIMAL)\n",
      "File \u001b[1;32mD:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\Classes\\trainer.py:83\u001b[0m, in \u001b[0;36mAccuracyTester.test_model\u001b[1;34m(self, max_depth, model)\u001b[0m\n\u001b[0;32m     80\u001b[0m label_train \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataset\u001b[39m.\u001b[39mdata[\u001b[39m\"\u001b[39m\u001b[39mpain\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     82\u001b[0m clf \u001b[39m=\u001b[39m RandomForestClassifier(max_depth\u001b[39m=\u001b[39mmax_depth, n_estimators\u001b[39m=\u001b[39m\u001b[39m400\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 83\u001b[0m clf\u001b[39m.\u001b[39;49mfit(data_train, label_train)\n\u001b[0;32m     84\u001b[0m prediction \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(data_test)\n\u001b[0;32m     85\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msum(prediction \u001b[39m==\u001b[39m label_test)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(label_test)\n",
      "File \u001b[1;32md:\\Programme\\Anaconda\\envs\\torchenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:331\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 331\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    332\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[0;32m    333\u001b[0m )\n\u001b[0;32m    334\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32md:\\Programme\\Anaconda\\envs\\torchenv\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32md:\\Programme\\Anaconda\\envs\\torchenv\\lib\\site-packages\\sklearn\\utils\\validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1072\u001b[0m     )\n\u001b[1;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1075\u001b[0m     X,\n\u001b[0;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1088\u001b[0m )\n\u001b[0;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32md:\\Programme\\Anaconda\\envs\\torchenv\\lib\\site-packages\\sklearn\\utils\\validation.py:909\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[0;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 909\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    910\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    915\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    916\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 207)) while a minimum of 1 is required by RandomForestClassifier."
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    subjects_test = not_processed[x*13: (x+1)*13]\n",
    "    subjects_train = [sub for sub in all_subjects if sub not in subjects_test]\n",
    "    \n",
    "\n",
    "    trainer_hyperparameter = {\n",
    "        \"path_train\": \"D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\FeatureGeneration\\dataset_processed\\INTENSE\\\\normalized_subjects_no_outliner.pkl\",\n",
    "        \"subjects_train\": subjects_train,\n",
    "        \"path_test\": \"D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\FeatureGeneration\\dataset_processed\\INTENSE\\\\normalized_subjects_no_outliner.pkl\",\n",
    "        \"subjects_test\": subjects_test,\n",
    "        \"acc_tester_metric\": \"AMI\",\n",
    "        \"wandb\": False,\n",
    "        \"acc_in_loop\": False,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"batch_size\": 256,\n",
    "        \"margin\": 0.09,\n",
    "        \"lr_steps\": 4,\n",
    "        \"filter\": [1,2,3,4,5,6]\n",
    "    }\n",
    "    \n",
    "    model_hyperparameter = {\n",
    "        \"sigmoid\": False,\n",
    "        \"dropout\": 0.35,\n",
    "        \"layers\": [207, 512, 64]\n",
    "    }\n",
    "\n",
    "\n",
    "    filter = lambda data: data[\"label\"].isin(trainer_hyperparameter[\"filter\"])\n",
    "    filter = None\n",
    "    \n",
    "    #model if needed\n",
    "    if use_model:\n",
    "        distance  = distances.LpDistance(p=1)\n",
    "        #distance  = distances.LpDistance(p=2)\n",
    "        #distance = distances.SNRDistance()\n",
    "        #distance = distances.DotProductSimilarity()\n",
    "        #distance = distances.CosineSimilarity()\n",
    "        model = EmbeddingsModel(model_hyperparameter)\n",
    "        trainer = EmbeddingTrainer(trainer_hyperparameter, model, filter=filter, distance=distance, device=\"cuda:0\")\n",
    "        trainer.trainloop(10)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    if use_model:\n",
    "        acc = trainer.test_accuracy(max_depth=16)\n",
    "    else:\n",
    "        #acc testet\n",
    "        acc_tester_hyperparameter = {\n",
    "            \"path\": \"D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\FeatureGeneration\\dataset_processed\\INTENSE\\\\normalized_subjects_no_outliner.pkl\",\n",
    "            \"subjects_train\": subjects_train,\n",
    "            \"subjects_test\": subjects_test\n",
    "        }\n",
    "        acc_tester = AccuracyTester(acc_tester_hyperparameter, filter=filter, device=\"cuda:0\")\n",
    "\n",
    "        acc = acc_tester.test_model(max_depth=16)\n",
    "\n",
    "    with open(saving_path, mode='a') as result_file:\n",
    "        results_writer = csv.writer(result_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        results_writer.writerow([\"split_\"+str(x), acc*100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOSO Crossvalidation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in tqdm(not_processed):\n",
    "\n",
    "    subjects_test = [subj]\n",
    "    subjects_train = [sub for sub in all_subjects_intense if sub not in subjects_test]\n",
    "\n",
    "\n",
    "    trainer_hyperparameter = {\n",
    "        \"path_train\": \"D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\FeatureGeneration\\dataset_processed\\INTENSE\\\\normalized_subjects_no_outliner.pkl\",\n",
    "        \"subjects_train\": subjects_train,\n",
    "        \"path_test\": \"D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\FeatureGeneration\\dataset_processed\\INTENSE\\\\normalized_subjects_no_outliner.pkl\",\n",
    "        \"subjects_test\": subjects_test,\n",
    "        \"acc_tester_metric\": \"AMI\",\n",
    "        \"wandb\": False,\n",
    "        \"acc_in_loop\": False,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"batch_size\": 256,\n",
    "        \"margin\": 0.09,\n",
    "        \"lr_steps\": 4,\n",
    "        \"filter\": [-6,-5,-4,-3,-2,-1,1,2,3,4,5,6]\n",
    "    }\n",
    "\n",
    "    model_hyperparameter = {\n",
    "        \"sigmoid\": False,\n",
    "        \"dropout\": 0.35,\n",
    "        \"layers\": [207, 512, 64]\n",
    "    }\n",
    "\n",
    "\n",
    "    filter = lambda data: data[\"label\"].isin(trainer_hyperparameter[\"filter\"])\n",
    "    filter = None\n",
    "    #model if needed\n",
    "    if use_model:\n",
    "        distance  = distances.LpDistance(p=1)\n",
    "        #distance  = distances.LpDistance(p=2)\n",
    "        #distance = distances.SNRDistance()\n",
    "        #distance = distances.DotProductSimilarity()\n",
    "        #distance = distances.CosineSimilarity()\n",
    "        model = EmbeddingsModel(model_hyperparameter)\n",
    "        trainer = EmbeddingTrainer(trainer_hyperparameter, model, filter=filter, distance=distance, device=\"cuda:0\")\n",
    "        trainer.trainloop(20)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    if use_model:\n",
    "        acc = trainer.test_accuracy(max_depth=16)\n",
    "    else:\n",
    "        #acc testet\n",
    "        acc_tester_hyperparameter = {\n",
    "            \"path\": \"D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\FeatureGeneration\\dataset_processed\\INTENSE\\\\normalized_subjects_no_outliner.pkl\",\n",
    "            \"subjects_train\": subjects_train,\n",
    "            \"subjects_test\": subjects_test\n",
    "        }\n",
    "        acc_tester = AccuracyTester(acc_tester_hyperparameter, filter=filter, device=\"cuda:0\")\n",
    "\n",
    "        acc = acc_tester.test_model(max_depth=16)\n",
    "\n",
    "    with open(saving_path, mode='a') as result_file:\n",
    "        results_writer = csv.writer(result_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        results_writer.writerow([subj, acc*100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15553fa20e7e98b2aa17988b3683b9c4372a086618e2f531c95263c140b6e43e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
