{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\Classes')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from models import ClassificationModel, EmbeddingsModel, SiameseModel\n",
    "from trainer import SiameseTrainerCombinationDataset, all_subjects_intense\n",
    "\n",
    "import torch\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = \"D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\TransferLearning\\\\results\\model_test_results.csv\"\n",
    "model_dir_path = \"D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\TransferLearning\\pretrained_models\\\\\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = os.listdir(model_dir_path)\n",
    "all_models = [model for model in all_models if model.endswith(\".pth\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_path in tqdm(all_models):\n",
    "\n",
    "    trainer_hyperparameter = {\n",
    "        \"path\": \"D:\\Workspace\\workspace_masterarbeit\\PainLevelShiftDetection\\FeatureGeneration\\dataset_processed\\INTENSE\\\\normalized_subjects_no_outliner.pkl\",\n",
    "        \"subjects_train\": all_subjects_intense[:1],\n",
    "        \"subjects_test\": all_subjects_intense,\n",
    "        \"wandb\": False,\n",
    "        \"log\": True,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"batch_size\": 256,\n",
    "        \"batch_size_test\": 256,\n",
    "        \"freeze_embed\": False,\n",
    "        \"dataset_ignore_subject_train\": True,\n",
    "        \"dataset_ignore_subject_test\": False,\n",
    "        \"decision_function\": 0,\n",
    "        \"filter\": [],\n",
    "        \"weight_decay\": 0,\n",
    "        \"lr_steps\": 10,\n",
    "        \"adam\": True,\n",
    "        \"number_steps\": None,\n",
    "        \"number_steps_testing\": None,\n",
    "        \"number_steps_histogramm\": None\n",
    "    }\n",
    "\n",
    "    model_embedding_hyperparameter = {\n",
    "            \"sigmoid\": False,\n",
    "            \"dropout\": 0.35,\n",
    "            \"layers\": [207, 512, 64]\n",
    "    }\n",
    "\n",
    "    model_classifier_hyperparameter = {\n",
    "        \"dropout\": 0.35,\n",
    "        \"layers\": [64, 32],\n",
    "        \"multiclass\": False\n",
    "    }\n",
    "\n",
    "    #init all models\n",
    "    classifier_model = ClassificationModel(model_classifier_hyperparameter)\n",
    "    embedding_model = EmbeddingsModel(model_embedding_hyperparameter)\n",
    "    siamese_model = SiameseModel(embedding_model, classifier_model, decision_function=trainer_hyperparameter[\"decision_function\"])\n",
    "\n",
    "    #load model\n",
    "    _ = siamese_model.load_state_dict(torch.load(model_dir_path+model_path))\n",
    "\n",
    "    #init trainer with model and hyperparameters\n",
    "    trainer = SiameseTrainerCombinationDataset(trainer_hyperparameter, siamese_model, device=\"cuda:0\")\n",
    "\n",
    "    #test model on intense dataset\n",
    "    test_results = trainer.test()\n",
    "    cm = test_results[\"cm\"]\n",
    "    acc = test_results[\"acc\"]\n",
    "    results = trainer.calculate_f_scores(cm)\n",
    "    recall = results[\"recall\"]\n",
    "    precision = results[\"recall\"]\n",
    "    f1 = results[\"recall\"]\n",
    "\n",
    "    #save results\n",
    "    with open(saving_path, mode='a') as result_file:\n",
    "            results_writer = csv.writer(result_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            results_writer.writerow([model_path[:-4], acc*100, recall, precision, f1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15553fa20e7e98b2aa17988b3683b9c4372a086618e2f531c95263c140b6e43e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
